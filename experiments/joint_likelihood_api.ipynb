{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal for the Gammapy Modeling and Fitting API\n",
    "\n",
    "This notebook outlines a proposal for restructuring and extending the current Gammapy modeling and fitting API to enable joint likelihood fitting. The proposal includes the introduction of new abstractions, represented by the following classes:\n",
    "\n",
    "* `SkyModelIRF`: a \"forward folded\" model, that applies IRFs to a `SkyModel` instance and returns an integrated quantity corresponding to predicted counts. It can only be evaluated on a fixed grid, passed on input. It is basically, what the current `ModelEvaluator` does now, but with the model parameters attached.\n",
    "\n",
    "* `BackgroundModel`: already integrated model, with fixed binning. It is initialized with a background map and introduces additional background parameters, such as `norm` or `tilt`. This model generic and not specific to 1D, 2D or 3D data.\n",
    "\n",
    "* `NPredModel`: combines a list of `SkyModelIRF` and / or `BackgroundModel` and joins the parameters lists and sums up the contributions from all model components in the list. This model generic and not specific to 1D, 2D or 3D data.\n",
    "\n",
    "* `Likelihood`: takes the binned data and model, updates the parameters and re-evaluates the model on every iteration of the fit. For different fit statistics sub-classes such as `CashLikelihood`, `WStatLikelihood` or `Chi2Likelihood` are introduced. This object is passed to the `Fit` object\n",
    "\n",
    "* `JointLikelihood`: takes a list of `Likelihood` objects, joins the parameter lists and computes the joint likelihood. This object is passed to the `Fit` object.\n",
    "\n",
    "\n",
    "Short term this code structure solves many uses cases without the introduction of `Datasets` and also replaces the current `MapFit`, as well as `FluxPointFit` and possibly `SpectrumFit` classes. Long-term we might re-introduce convenience classes, specific to certain tasks.\n",
    "\n",
    "The use cases that can be solved with the proposed structure are listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.cube import SkyModelIRF, BackgroundModel, NPredModel\n",
    "from gammapy.utils.fitting import CashLikelihood, JointLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 1: Simple Fit with Background Norm\n",
    "\n",
    "Simple fit of a model to one observation, equivalent to what `MapFit` does now but with additional background parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnde_model = SkyModel()\n",
    "\n",
    "# the exposure-map can have a different geometry than the background and exposure map, only after applying\n",
    "# the PSF and Edisp it must be the same. This a natural place to introduce over oversampling for evaluating\n",
    "# differential models\n",
    "model = SkyModelIRF(exposure_map, psf, edisp, dnde_model)\n",
    "\n",
    "background = BackgroundModel(background_map)\n",
    "\n",
    "npred = NPredModel([model, background])\n",
    "like = CashLikelihood(counts_map, npred)\n",
    "\n",
    "fit = Fit(like)\n",
    "\n",
    "fit.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2: Joint Fit across Multiple Observations\n",
    "\n",
    "This use case involves a joint fit across mutiple observations with varying IRFs, but the same model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnde_model = SkyModel()\n",
    "\n",
    "model_1 = SkyModelIRF(exposure_map_1, psf_1, edisp_1, dnde_model)\n",
    "model_2 = SkyModelIRF(exposure_map_2, psf_2, edisp_2, dnde_model)\n",
    "\n",
    "\n",
    "background_1 = BackgroundModel(background_map_1)\n",
    "npred_1 = NPredModel([model_1, background_1])\n",
    "\n",
    "background_2 = BackgroundModel(background_map_2)\n",
    "npred_2 = NPredModel([model_2, background_2])\n",
    "\n",
    "\n",
    "like_1 = CashLikelihood(counts_map_1, npred_1)\n",
    "like_2 = CashLikelihood(counts_map_2, npred_2)\n",
    "\n",
    "\n",
    "joint_like = JointLikelihood([like_1, like_2])\n",
    "\n",
    "fit = Fit(joint_like)\n",
    "fit.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 3: IRFs per Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnde_model_1 = SkyModel()\n",
    "dnde_model_2 = SkyModel()\n",
    "\n",
    "\n",
    "model_1 = SkyModelIRF(exposure_map, psf_1, edisp_1, dnde_model_1)\n",
    "model_2 = SkyModelIRF(exposure_map, psf_2, edisp_2, dnde_model_2)\n",
    "\n",
    "background = BackgroundModel(background_map)\n",
    "npred = NPredModel([model_1, model_2, background])\n",
    "\n",
    "like = CashLikelihood(counts_map, npred)\n",
    "\n",
    "fit = Fit(like)\n",
    "fit.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 4: Joint Likelihood with Fermi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnde_model = SkyModel()\n",
    "diffuse_model = SkyCubeDiffuse()\n",
    "\n",
    "model = SkyModelIRF(exposure_map, psf, edisp, dnde_model)\n",
    "\n",
    "model_fermi = SkyModelIRF(exposure_map_fermi, psf_fermi, edisp=None, dnde_model + diffuse_model)\n",
    "\n",
    "# or alternatively precompute the diffuse emission as background model\n",
    "fermi_diffuse = SkyModelIRF(exposure_map_fermi, psf_fermi, edisp=None, diffuse_model)\n",
    "background_fermi = BackgroundModel(fermi_diffuse.evaluate())\n",
    "\n",
    "\n",
    "background = BackgroundModel(background_map)\n",
    "npred = NPredModel([model, background])\n",
    "\n",
    "npred_fermi = NPredModel([model_fermi])\n",
    "\n",
    "# or with the precomputed background\n",
    "npred_fermi = NPredModel([model_fermi, background_fermi])\n",
    "\n",
    "\n",
    "like = CashLikelihood(counts_map, npred)\n",
    "like_fermi = CashLikelihood(counts_fermi, npred_fermi)\n",
    "\n",
    "joint_like = JointLikelihood([like, like_fermi])\n",
    "\n",
    "fit = Fit(joint_like)\n",
    "fit.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case 5: Joint Likelihood with 3D and Flux Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model = SpectralModel()\n",
    "spatial_model = SpatialModel()\n",
    "\n",
    "dnde_model = SkyModel(spectral_model, spatial_model)\n",
    "\n",
    "model = SkyModelIRF(exposure_map, psf, edisp, dnde_model)\n",
    "\n",
    "background = BackgroundModel(background_map)\n",
    "npred = NPredModel([model, background])\n",
    "\n",
    "like = CashLikelihood(counts_map, npred)\n",
    "like_fp = Chi2Likelihood(fp_data, spectral_model)\n",
    "\n",
    "joint_like = JointLikelihood([like, like_fp])\n",
    "\n",
    "fit = Fit(joint_like)\n",
    "fit.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is **just a first proposal** and of course there are many details to be sorted out. Open questions are:\n",
    "* Where does the model.evaluate() call happen? Right now it is in the `Likelihood` class (see draft implementation below), does this make sense?\n",
    "* How to handle masks during the likelihood evaluation and masks for joint-likelihoods (see draft implementation below)?\n",
    "* Is the extra-abstraction of an `NPredModel` needed? \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood(object):\n",
    "    \"\"\"Binned likelihood object\"\"\"\n",
    "    def __init__(data, model, mask=None):\n",
    "        self.data = data\n",
    "        self.model = model\n",
    "        self.mask = mask\n",
    "    \n",
    "    # this method is the interface to the optimizer \n",
    "    # could also be named evaluate_fit() or similar\n",
    "    def __call__(self, factors, mask=None):\n",
    "        \"\"\"Evaluate the likelihood for the fit\"\"\"\n",
    "        self.model.parameters.set_factors(factors)      \n",
    "        return self.total(mask)\n",
    "    \n",
    "    def per_bin(self):\n",
    "        \"\"\"Evaluate the likelihood per bin\"\"\"\n",
    "        # IMPORTANT: it is not clear where the best place for the model evaluation call is.\n",
    "        model = self.model.evaluate()\n",
    "        likelihood = self.evaluate(self.data, model)\n",
    "        return likelihood\n",
    "    \n",
    "    def total(self, mask=None):\n",
    "        \"\"\"Evaluate the total summed likelihood and apply optionally a mask\"\"\"        \n",
    "        if self.mask:\n",
    "            mask_default = self.mask.data\n",
    "            if mask:\n",
    "                # TODO: re-think how to combine the masks\n",
    "                mask = mask & mask_default\n",
    "            stat = self.per_bin[mask]\n",
    "        else:\n",
    "            stat = self.per_bin\n",
    "        return np.sum(stat, dtype=np.float64)      \n",
    "\n",
    "    \n",
    "    \n",
    "class CashLikelihood(Likelihood):\n",
    "    \"\"\"Cash statistics likelihood\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : `Map`\n",
    "        Counts map\n",
    "    npred : `NPredModel`\n",
    "        Predicted number of counts.\n",
    "    mask : `Map`\n",
    "        Mask to apply.\n",
    "    \"\"\"\n",
    "    def __init__(self, counts=None, npred=None, mask=None):\n",
    "        self.counts = counts\n",
    "        self.npred = npred\n",
    "        self.mask = mask   \n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        \"\"\"Alias for a nicer documentation\"\"\"\n",
    "        return self.npred\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"Alias for a nicer documentation\"\"\"\n",
    "        return self.counts.data\n",
    "    \n",
    "    # This is a static method using pure numpy, because users might want\n",
    "    # to call it directly CashLikelihood.evaluate(counts, npred), instead\n",
    "    # of our current cash(counts, npred)\n",
    "    @staticmethod\n",
    "    def evaluate(counts, npred):\n",
    "        \"\"\"Cash likelihood formula\"\"\"\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            value = 2 * (npred - counts * np.log(npred))\n",
    "            value = np.where(npred > 0, value, 0)\n",
    "        return value\n",
    "    \n",
    "    \n",
    "class Chi2Likelihood(Likelihood):        \n",
    "    def per_bin(self):\n",
    "        \"\"\"Evaluate the likelihood per bin\"\"\"\n",
    "        model = self.model.evaluate(parameters)\n",
    "        \n",
    "        likelihood = self.evaluate(self.data, model, model_err)\n",
    "        return likelihood\n",
    "\n",
    "    \n",
    "    @statictmethod\n",
    "    def evaluate(data, model, model_err):\n",
    "        return ((data - model) / model_err) ** 2\n",
    "\n",
    "    \n",
    "class JointLikelihood(Likelihood):\n",
    "    \"\"\"Joint likelihood across mutiple likelihoods.\"\"\"\n",
    "    def __init__(self, likelihoods):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        likelihoods : list of `Likelihood` objects\n",
    "            List of likelihoods to be combined.\n",
    "        \"\"\"\n",
    "        self.likelihoods = likelihoods\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        \"\"\"\"\"\"\n",
    "        return ModelProxy()\n",
    "        \n",
    "    def per_bin(self):\n",
    "        # As the binning can differ for different likelihoods this\n",
    "        # does not make sense. Which in turn means you can't fit joint\n",
    "        # likelihoods with optimizers, that rely on the per bin likelihood\n",
    "        raise TypeError()\n",
    "    \n",
    "    def total(self, mask=None):\n",
    "        \"\"\"Total joint likelihood.\"\"\"\n",
    "        joint_likelihood = 0\n",
    "        \n",
    "        for like in self.likelihoods:\n",
    "            joint_likelihood += like.total(mask)\n",
    "            \n",
    "        return joint_likelihood\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
